{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing usps from pickle file .....\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from data_fetch import prepare_usps_mlfetch\n",
    "[Xtrue,Xlabels] = prepare_usps_mlfetch()\n",
    "data = Xtrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvgAAAITCAYAAAByoWiiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAIABJREFUeJzt3XmYbFV59/3vLZOACioRHMGZOEZxAo0IakSN4hhxCKgx\n+qgomjyJUVGO06uJBhWcHo1DUKMG4hglJAqKopI4gDEmggyiaJB5OoJwzv3+sda296lTVV3dXd3V\nvc73c111Vfce19577VW/2rWHyEwkSZIkteEGsy6AJEmSpOkx4EuSJEkNMeBLkiRJDTHgS5IkSQ0x\n4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHg\nS5IkSQ0x4GtRIuL+EfGFiLgwIjZExMaIeO2sy7UliIgj6vr+0KzLMi0R8RHr0OxFxL51O5w967LM\nUkScW9fDQ2ddltUuIg6p6+rEWZdlGuqybIiI2826LCttuT5bIuKrdboHT3O6Gq+ZgB8R20fECyPi\n8xHx04i4OiKuioizI+LYiHhmRNxw1uWchohYV3fEm8xo/ncCTgIeA+wMXAj8L3DVhONv7L0OHTPc\nVr3h/KDdVM66AFOWTGGZImKXiPhNrTOXRsR2UyibtjxTqY99EXFgbbdtyyawJa2vLWBZp74/tSQi\nDqvbf6pfKree5sRmJSIeB/w/YDfmKtHVwEZg9/p6MvDXEfGszPzqLMo5Ra+lLOeHgStmMP/nAzsA\nXwMen5lXLmIa3XZ6ZUT8XWZeM8GwmhOzLsAq9UxKu5bATYAnAJ+aaYmk4gnAIZS6efKMyzJNlwP/\nA/x0ytOd1fr6MSU7XLeC81wtdeMiyrb85ZSnex5lvV4+5em24mXA7SgHTs+b1kTX/BH8iHg28Blg\nV+C/gWcBu2TmTTJzZ8oR5qdQVtwtgVa/Ia+ku1MaomMXGe77dgNesvQiSQAcTKmbH6B8CTpktsWR\nNtHcwYrM/Gxm3i0zn7Mck1+GaY6fYebvZubdM3PaIXfeWa/w/DYvQOa767Z89ZSne0id7uemOV2N\nt6YDfkTcC3gv5YP8i8B9M/MTmXlpN0xmXpmZn8nMhwMHAUsNpILt6/tEp+SMcTxl2/1lRNxoidPS\nFi4i7gHcB/g58GeU+vmIiNhtpgWTJGmlZeaafQFfoPyUdh5w4yVMZ1tKIPg2cBmwnvIz1d8Cu44Y\n54g67w+Nme5H6jCvHei+b+1+dv3/wcA/U85lXw+cBrx4zPQ21PfB18iyjChfAH8CfBW4GPg1cDbl\ndKc7Dhn+3BHz/e2yTDjfbhkeR/lZdwNwxJDhtuoN+9AR07oxsK6usyvr6/Ta7Sbzbbu6Dg4FTgUu\nrd3vNbj9gG2Aw4EfUU7/+inwTmDn3nT3Aj5N+XlzPfDvwIFj1sPv12l8GzgfuBa4gPLF58ljxpu3\n7i3DPPvr4gaUnxRPr+viYsq+uNc8835gHe7iup2+D7y0boMP1+382oUuU2/6b6tlfEv9/5g6zf87\nZpxF7YtTaD8OqfM9sf7/dOCblJ+wf1Xr0Z694XcDjgbOoeynZwKvAG4wYvp3rtvqK5R9+te1fn+r\nlvWGk6yPEcPs16vn19b3TwP7jRh+9zrNDZNuh4F+2wCHAafUZfgN5Zqf04B3AQ9aZH15Zl0fV9Y6\n+RXgMbXfOQxpd2rdfzSljfxOLce1lH1p6DroLdvI18Dw9wHeAnyd0s5cQzl14iRKez1qmw+2ay+n\n7KNX1fE/B9x/nnWymPZ0k7o80O/c2u+hwE2BI2t9vIbyRfz9wG5LXF97UA70/Ziy711d53sS8FfA\nzRZYL7rPnNuNWr+95T6Vcprs5cCJwCMWOK+Jl5XN26pHU9rtC2p5X9obduqfLf31AtyW8ivpz+q2\nPBt4KyNyGCVjbAQOHrffs7j2d2fg7ZR99hpKHvwAcJvB6S9w2yyqXlHau6MpnwFX1/rxHeAvgR1G\nrO9Rr832qQUtw1JGnuULuFWtbBuAP1/CdHYBvtervOspH9JdiL4YeMCIHWHDsB2hN8zQ0NKvdJRG\n4jrgeuCS3jJtBI4cGO8dwC96Zb2g/t+9jlzAcm8PnNCb1jW9+W+s6+HxA+OcWudzTR3u0t68v72A\neXfz/APgefX/S4GbDgw3NuADd2LuA2QDcx9I3TKcy/AvKt22+zDl9K6NlNBwcd0OXcDvtt8bKedF\nbqg77NW9eZxKCXgHUkJUfzt25XrKkDLs2Ou/oda5Swe2/3tHrL9FBfwlzrNbF68H/qUOew3lg60b\n92rggSPGP4hSz7t5XUz50NkAHFunv9mX4QUs2w1qPdwA3Lt2e1Sd5n+OGW9R++IU2o/fhiJKmNtY\n10d/3F9R6vidKR+k3Tb7TW+Yo0eU6z965b+a8oF5/UC93XHc+hgx3Tf2lvV65vaZbrpvGjLOogM+\npQ346pB5dutgA/APi6gv7+pN87qB5XgJowP+3dl0H7qU8gHeryuvGBhn71o3u3bjCjZtt88fGP7C\n3vS6Lx/96X+BISGfTdu1f+rVqX57dB3w1BHrZLHt6biA363HZ9bxu+mu7033LGCnxawv4L6UNqj/\nOdZfXxuAP1hg3RgX8DdQvkB9gLnPja4N3Vjr0BMXMK+FLGu/rfqz3vy6/eGldbilfrYMzTW9aT6e\n8oWxm/a1vemeCmw1ZNyT6jAjAz6La39vXetYV7armPtMuoDyhXjBAX+x9Qp4EnN1u6vrXV7aSPmy\n/Du94f+8bufus/Gige1/7ELbtk3Ks5SRZ/kCntFb+XdZwnSOr9O5qG6c6G3g02q/XzDwbY3JjuDP\nF/CvooTCd3QbnXJh4Dt6O+/vjtnRbruE5X4fc0H+ecA2tfudKEeyNtbKeach4w7dWRcw737A34py\nNHID9chrb7iRAZ9yVO905j549u/126+30/+gW7Yh2+6KuvzPpx7RpAS2G/W2X/fl43zggNo9KL8+\ndA3Jm+sw7wduUYe5OeWI3kbKkaobDJRhe8rFn49j018BbgK8kLnQsNnRlknq3oj1vpR5duviEkoA\neTKwde13j7otNjDkix5wB+YavS8Bu9fuN6T8EnAdcx9Aiw34j67l++FA/fnfOt37jhhvqfviYtuP\nLhRdSvkAOLRXB+9OuZ5oAyWofRv4BnCP3np7Za9cdxtSrqOBZ9NrIyj7zGN7097sywHjj6QfxNz+\n+I5umShHZt/R6/eMgfGWEvD/mLm26OnAtr198Da13r5i1HRHzOuZvbK+hXpkGvgdSj2/ttaHYe3O\nnSnh7uHUdqLXbryKuYCy2ZFyJvyVCvgY8FRqW9Lbd59BaYeGHtRirl3ofuV4KbBd7Xd75r6YXwXc\nfmDcpbSnkwT8SyhHMR9Qu98A+EPmgtxbFrO+KF+QN1B+3blXr/sNKfvg3zLioMOYaY4L+F0beDXw\np8zts7tTPheHtvcTzHOSZe32kfV1+x7FXFu1LXCrXl2Z+mdLb71cAvwrtT2sdefZlPZzA/B/how7\nX8BfbPv7Veba2AN63R9E+bX9EhYX8Bdcr4D7U9qOa4HXAbes3YPy6/WptSzHj9lPfn8h5Zx3OaY5\nsZV8AW/oKvsSpvGQXqXd7Kc14BbMfWtbN+mO0BtmvoC/AXjfiHG7wHT4kH5DG6AFLPfuzB2tet6Q\n/tszF7o/MqT/1AJ+/b/7wL2K3ikNjA/4z2LuKPKwHf9uzB1ZePaIbbcB+JN5tl833EOG9D+cuZ/S\n/m1I/x2Y+xKw2fjzrKNunXxlSL9FBfwlzrO/LvYe0v++vf63Gej3wdrvR9SANtD/Vb1xFxvwP1XH\nf+VA93fWab9zxHiL3hdZWvtxSG/cYft4N+3uy8NmP30DXx41/jzrandKQLiSgVN1GB/wuzbhYyOm\n+/E67llD5rfYgP/uOs93T7Ge/6RO84Mj+v8rI9qdCabdtQmbTZvpnIb24GHruPbrt2t/NaT/dsx9\nuXv/QL+ltKfzBfwugO08pH93JPoni1lfzB35Hnvq0QLX8XwBfwNw0JDxbsnc0dqFtvcLCfgbgI8u\nYfkW9dnSm/fpDHzJq/2PqsN8eUi/+QL+YtrfhzEX/jc7TY/S7nT1Y6EBf8H1inIQZmimqv13Zu4L\n+n0H+nUBf0HtzXyvtXyR7c3r+6VjhxrvKfX9O5n55cGemfkrypHuAP5oCfMZ5y0jun+uzvceyzDP\nJ1KOoPwvJXxtIjN/DfxNnf+TImK5b8n4D5Twtz0w6dX7T6HcdeBzmfnfgz0z80fAcYzfdhdTGtb5\nfCszvzGke1dnkiHbMTPXU46+wsK34xfr+4NWYP0vZJ5fz8xvDXbMzO9RjlzB5sv6RMo6OjIzfzNk\nmu+kHJValIjYiXK0CuATA70/Xt+fHhHz3RZ4ofviNNqP31DOHx10CiUsJOXn9GE3B/jKiHKNlZk/\nBf6L8gX09yYZJyJ+D7hj/fdNIwZ7XX3fIyIesJAyjXEFZRlvOY2J1eW4Q/131Pb+/5Ywi3+u7w9e\nwjRGysxTKKdF7DHm4vH1lH1qcNxrKUceg/ILXN802tORxQb+X2ZeNqTfZ+v77SNi+yH959PdJnoq\n9WNC52XmJwc7Zrnrzr/Xf5fjc7vvbUsYd6mfLUdm5rBbiHbbcrHLvtD290n1/ZTM/PZAv66d+ySL\nu6X0gupVRNwB2Ieyb35o2DC1/h9f/33kIsq0YGs54E/DfSmNz0ljhjmxvt9lkQ3QOJdk5rkj+p1f\n32865XlCWW4oYS1HDNMt947AXZehDL9Vy/Bayo74pxFx2wlG65Zhkm133xH9v5OZG+crHvCfI/r9\nqvf3D0cMc0F932w71gd5/UlEHB8Rv4iIa7oHe1F+WoTyk+DU6sAS55mUc7tH2azO1oZv5/rv0Ps7\nZ+bVwHcXshwDnk4p87cG96fM/HfKOb43p5yeMspi9sVptB/n1uXfRN0nLqr/LrhuAUTEIyLiExHx\nk/rgv429bX3vOtitxpS9r9uHLhwWAGuZz2BuXY3a5xaq+0B8QkR8LiKeGBE3W8L0unJdkJlnjhjm\nm5SjgkNFxA0j4uURcVJEXNB7sNpGyvUYMPl6HTWPp0bEZ+pDG9cPbLtufxo1j+/UgzTDfK2+7xwR\ne/S6T6M9Hec7I7qf3/t75xHDjPMlyufGRyPizRHxwAm+yC/VqGWB5f3c7vw6M08fN8Ayf7bMty0X\nM83FtL/3obS/ww6+db6+iLLAwuvVPvX9RsD5EfHLYS/gaXW6k2ScJVvLAf/i+r6UHel36vv5Y4bp\njkoG5TzLaRp3y87uwU/bTHmeUJY7mWy5u+GXVWZ+mvLhuC0l7M9nIdvu5iP6XzhZ6UY+9GND90dm\nXjDPMJtsx4jYkRJ4P0C5FmFXSqj4FeWXlf/tDb7jhOUca0rzXGid7dedX4wZd9x2nM8hlPo8ePS+\n83HK/nvwmGksZl+cRvsx7l7bG+YZZmjdAoiIoyinmvwR5fzrrShtZredu19SJq1bkywrzC3vVNqM\nzDwZeA3l3PY/pFyTcFFE/Cgi3lqfqr0QXblG1sX6K9NFw/rVo+anU46EP5SyTa9hbh/q2pRF7bM1\nmH2acsrZ4ynXGcDc08L/l3Jawrh5jNtG/X6/M+TvpbSn4wzdv+qvCp3FfNb9BeXXrhtR7ir1LeCK\niPhKRPyfWJ6n18/qc7tz8bieK/DZMmr5u2VfzBesxazTrj0d14aO+8wZZ6H1qjvSvzXl1MxRrx0o\nn1XTPlg81FoO+N1RpO0i4i5LnNZyNAJrwWpb7tdQH060gA/upSzDhvkHWTavpdxB4UJK8Nw1M2+U\nmbtl5q2Y+2CH6T21dhbzXFYRcWfKBUwAR/ePdPaOWHVfGB+7xKO/o6yq/SgiDqBctHs95ZzaO2Xm\nDTPzdzLzVnVbd6cSLHQ7r/iyZuabgLtQLiz+F8p1LXel3IHiRxHxrBUszjspF9qeRTlF4GZZHqrY\n7UN7L3H6z6c81fRqyt18bpuZO2Tmrr1t14WW5dhHV1Vdnk9mXpKZv0855eGdlINE21DOz34P8MOI\nWNKvKavQfJ9bzbXzK20R9arL0qdn5lYTvP5kJZZjLQf8rzH35LfHL3Ia3dGW240ZptsZ+j+Zw9xP\nuOMaxJ0WWa7ldiFlx55kubvhl11mHk/5eXwr5s7nHWUh227sEY8Z6c55PTQzP56Zg0cMd21knv26\nM+6DdrEfws/u/Z3zvLahnM4zLUtpP5bTU+v8PpCZb8zMc4YMs9Bt3S3rfD8t9484d357uktEbDti\nvLFtZWb+NDP/JjMfA9yMcmeXr1GOmL0nIib9dbUr18j6FhHbMOTXltr98ZR1+4zM/FxmXj4w2FL3\noW4ffX1mviczNzkCGRE3GFa2AZPuZxcO+XtNtqeZeWJmvjwz70dZPy+glPP2DL/GpWWzaOdnoVuu\ncefJL+najAXUq+4X/BU59WZSazbgZ+b5zJ0n9ZJJn4Q6cFHJ9+r4+44Z5eH1/YyB8xq7C4Zuw2h7\nTVKmRei+2Cz223d3nugDx/yE2S331ZQHPayUwynL9TTgnmOG67bdfmOG2b837GrT1ZvTRvRfjotw\nVnyemXk2c/vKQ4cNExE7APdb6LTrvvwsyv7wIsrpeqNef0X9dWih8xljKe3Hchq7nSPidpTb4S5E\ntw/tGBFDt1X9NeXWA8PD3Pbvl23Q/SctSBYnUy6svo5ymsGk9acr165jfiXch+GnGexCuRMNjN6H\nHjFm3t2pNePa7fn20Ycw/1H2+41p1x9W3y8bOOd5Nbank6yvzWTm5Zn5d5QbNsy3f64Wi1rWEWbx\n2TIL36esr4eMGeb3pzWzeepVd+OJm0XExG1ZzzS3/2+t2YBfHU65dddtgH+IiO3GDRwRT6M83a9z\nXH2/e0Rs9itAROxK+caWlHMi+7oLL+9fhxsc91ks37e57grvxVyUBHP3Z7855SfhTdSLAf8vZbn/\nacyFuFOXmV9l7u4gbxgzaLftHh0R9x7sGRF3Z+5IxuC2Ww26I3+bfYmp51C+qpF5QjlvOoCX1aOg\ngw6jnJu4UPtR9rENlAeCXDHqRbmbAsBeEfG7i1mIIZbSfiynkdu5ejMLD02nUW4vCaPrSfer2zn1\n4uZu3O4JkFAeCLeJiLg55VkcmxlRXzrdw65gLniPNbAcrxgx2CtHdL+SuYMrw/ahW1JOqxmluyPQ\nuHZ73D66FeVBY/PZkbJPDY6/LeXzLykPl+tbje3p2PUVxVZjxu++UE9UN2ZskroxqVm18yvtM/X9\nwRHxwMGe9UDGQcztsxNZTL3KzB9T7pgXwN+MGz8ith/yS+ZSM91Qazrg1yvJX0zZgH8IfD8inhkR\n/bt43CQinhQRJ1EuwrtRb/xvUM7pDODDEfHk+hMoEbEX5SK1m1IuSjlqYPanUM6F3Bb4ZHdHgrrx\nXkB56NElLI//qu8Hd+VdiMw8j1K+AP46Iv60q3D1eoYvUY7wrWf0LfGWU3cU/zFjhvkU5aErAXwu\nIrojpdS/v0g5JeOHlNtwrjb/Rin7kRHx2yPb9dv/iZTTEFqYJ5RAeQ3wu5RttUed7w0j4mWUp+MO\nu4XefLqj8Sdn5th9LTN/xtzdH6ZyFH+J7cdy6rbzCyLiOV1IjojbRsTfU34dW0zb1O2XB0bEUd31\nDBFxs3pRb/dheviQcf+xjnt4RDyu+wCMiAdRbjc7KsgfExEfiog/6P9KGxG7A8dQjmb/moXdLWNd\nLctzI+ItUW6zSkTcIiI+TDnKPezORlcx9yH+oS4I10DwcMpDd8bp2u0DYvQtLrtt95qIeHyvPu1J\nuQXn/YaVbcDlwBsi4qXdkfwod7P6PGUfvAb464FxVmN7Ot/6ugnwk4h4VUTco7euuu3xJkp9/JeV\nKe6STFI3JjWrdn5FZeZJlP3+BsCno1x7BPy2XfkXygHghR4VX2y9emmd377AiRHx4IhyxkhE3CAi\n7h0Rr6M8tXdwG/9XLefT5ztQvSA5xZvqz+pFOS/yl8w9Dngj5RvR5b3/N1AujHrIwLi7UG7R1427\nnk0fUXwhQx41X8d9AnOPGN7Ipo+R/wBzDwca9aCrkQ9fYPzDQ57dW671lKNj5wB/s4B1tj2lgnZl\n7x5p3i33euAPR4w79KEVC5j3Jg+6GjHM5we23WYPgKDcl/vs3jJcVV/dOGcz/NHqIx/mMTDc0O3X\n6797N6+FToNyDt8FA/XuSuae2vmI3nKMeuDKQp9ku5R5jl0X89ULSqj8TW/el/T+/0fgI/NNf2B6\nOzL3tNEXTjjOK5h70mT3xNml7ouLaj/GTbM3zNiHn4yaBiWIndIr03Vsum+/etS2mm99UL6MddO9\nnnI+6vW9ab9xxHg7M/eAqY2UUN7VvbOZezL54IOuPtMbp3uKZrePb6x16Bmj1uGYdXvUwPrpP4b+\n0FHrHnhAr951+83V9e9fUU4bGtomUH4xvaiOez3lANE5lF88umFuCpzRm/61lM+VblkPHlO2rl34\nMOWI/GC73k3jqSPWyWLb03H7x9g6XIcZ1eaMXV+U6zY2sum6uqhuz677GdQnvC6gbiy63WWCdnLE\neJPUjXnbqjrcsny2jBqn13/k5yGLbG8mqF+37dWxjZR98Yr69y+B59a//3sB22LR9Qp4FHNPZ+7a\nuQsp+123D15P7wnjdbz9ev2vAc6ry/WJhdSjwdeaPoLfyczPUx5e8mLKkYafUS7U3Iqyko6lXFy3\nZw48sCjLBSh7U05J+Q/KhtiGsgHfTnk8/L8zRGZ+lnIbqpMoleoGlPMTn5uZf9oNNqrYY/qNHSYz\nP0L5SftUSqW7DeXiqIlvX5blfOBH1+mcTNkxtqd8WfgAcM/M/OeRE1i6+Zb9NZTKPnI9ZeZZlPt5\nv55yylQ37H/Wbveuw4ya/yQ/3U1jmGHb8BxKWPgYpTG+AeWhbR+lPD3vy6PG7XWfpGzTnueiZOan\nKA//+WKd5zaUoxaHZeYfsfDleQqlvm5k7qfa+fxTncdubHoe6lL2xUW3HwuY74LKleUhNI+gPDjm\nLMqHzXXACZQv7fP9Kjdun3st5bqCz1I+uHakfPh9Fnh4Zg47ek+Wh7zsTfnl8HzK0aqLKHeo2Kt2\nGzbfVwB/Sbkf/lmUdXsDypeFD1KeCLngI8qZ+VLK9RvfZu42fCcBj83Md3WDDRnv3+tyfJbyQb41\nZV96L+W+3D8YM+7FlF8HPk35MrALpd2+bW+YS4EH1en9rE5nfR3noZl5zKjp92dFudD65ZQHCG5T\ny/p5ylOoB0/P6ea9XO3potrQCdbXFZRnW7yD8ln4K8ov9FdR7hL1KuA+OXCh8oSW+rm9sJlNUDcm\nnf8yf7ZM6zNz0vmNHSbLL7P3pXxh/yllWS8D/o7ya1d3QfhCfiFedL3KzBMod/x6I+XAzzWULwyX\nUQ66vBm4Xy13f7yTKAeMv0rZ329F2f63WEC5N9MdxZIkSWtURBxBOQL7kcx87qzLI81aRLyB8ovl\nFrlPNHEEX5IkSYJybRDlFJ2kXJewxVlywK8XWD0vIj4dEWdGeaz2ZRHx9Yh4bneRQW/43WPIw2h6\nr5E/t0bEIRFxakRcWedxUkSMe/y8JEmSGhMRD6gX/O/VXZwa5WnQ+1NOubsl5TTtf5plOWdlMY8U\nHvRUyvmCv6Cs0PMoD1J4EuU8qAMoj0sfdBrlPMZBPxw2k4h4G/BnlPMS30+5e81BwBci4tDMfM/S\nFkOSJElrxI0pF8UfChARl1KuC9qWuYcLPi0zfzOzEs7QNAL+j4HHZeYX+x0j4lWUi86eHBFPzMzB\nC+FOy8zXTzKDiNibEu7PpFwkckXt/lbKRa1vi4h/znL7R0mStkQLvvheWsNOo5xj/0jKjVZuQbnR\nwRmUC/OPzMwLRo/etiWfopOZXx0M97X7r4D3Ue6W8LAlzuaFlEbrTV24r/M4D3g35YEDz1niPCRJ\nWpMy83WZuVVm/smsyyKthMy8ODPfnJn7Z+YemblDZt4kM++Vma/YksM9LP9FttfV9+uH9LtVRDw/\nIl5Z30c9dRHmHp99wpB+x1O+ROw/pJ8kSZK0RVm222TWJxWeBtwNOCAz/612351y0cPgjINyD9BD\n+vcIjYgdKPcfvTIzdxoyn5tT7sd8QWbechkWRZIkSVozlvMI/l8Ddwe+2IX7aj3loRl7UZ7ad1Pq\no30pp/J8OSK27w3fhfrLR8yn677zdIotSZIkrV3LcgQ/Il5KeQrYj4CH1KcYzjfOVsA3KE9ge1lm\nHl2735LylMOfZ+bthoy3NeWiimszc/vB/kOG9wIkSZIkrYjMjPmHmq6pH8GPiEMp4f6HwP6ThHuA\nzNxAua1mAA/t9eqO0G92es5A94U8iliSJElq0jRuk/lbEfEy4EjgB8AjMvOiBU7iwvq+Y9chM9dH\nxPmUi3J3HXJV9J3r+xkLmdFyXXsgLUVEWDe1Klk3tZpZP7UaDTzrdUVN7Qh+RLyCEu6/B+y3iHAP\nsHd9P3ug+4n1/YAh4zymvn9lEfOTJEmSmjKVc/Aj4jXA6ygPtnrUuNNyIuI+lIdc5UD3hwP/THkC\n2YMz89u9fnsDpwA/AR7QTT8i9gC+C2wP7DnJg666c/D9pq/VyKNQWq2sm1rNrJ9ajboj+LM4B3/J\nAT8iDgE+TLnX/bsYfrebczPz7+vwJ1FOq/km8PPa/16U+9gncHhmvnnIfN4GvJxywe1xlC8CTwNu\nBhyame+dsLwGfK1afkhptbJuajWzfmo1WusB/wjgtfMM9rXM3L8O/xzgicA9gF2AbYALKIH/3Zl5\nyph5HQy8mHJv/Y2Uo/dvzczjF1BeA75WLT+ktFpZN7WaWT+1Gq3pgL/WGPC1mvkhpdXKuqnVzPqp\n1WiWAX85H3QlSZIkaYUZ8KVV5Igjjph1EaShrJtazayf0qY8RUeSJEmaMk/RkSRJkjQVBnxJkiSp\nIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkh\nBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEG\nfEmSJKkHRQDuAAAdnElEQVQhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmS\nJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIk\nqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSp\nIQZ8SZIkqSEGfEmSJKkhW8+6AJIkSWtZRMy6CNImPIIvSZIkNcQj+JIkSVORsy6AVpXZ/bLjEXxJ\nkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmS\nJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIk\nqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSpIQZ8SZIkqSEGfEmSJKkhBnxJkiSp\nIUsO+BFxs4h4XkR8OiLOjIj1EXFZRHw9Ip4bETFivH0i4ksRcXEd5/SIOCwiRpYpIg6JiFMj4so6\nj5Mi4rFLXQZJkiSpFZGZS5tAxAuA9wK/AE4CzgN2BZ4E7Awcl5l/NDDOgcBxwK+BTwGXAI8D9gSO\nzcynDZnP24A/A35Wx90WOAi4OXBoZr5nwvImwFKXW5IkCWDuWKbZQn2lXmTm0IPdyzrnKQT8hwE7\nZuYXB7rfAvgP4DbAUzLzM7X7jYGzgBsD+2Tm92v3bSlfEB4EPD0z/7E3rb2BU4Azgftn5hW1++2A\n7wE7AHtm5nkTlNeAL0mSpsaAr+FmF/CXfIpOZn51MNzX7r8C3kdZuof1ej0V2AX4RBfu6/C/AQ6v\nw79wYHIvpOw1b+rCfR3nPODdwHbAc5a6LJIkSdJat9wX2V5X36/vdduPEtZPGDL8ycB6YJ+I2GZg\nHEaMczzlS8H+SyuqJEmStPYtW8CPiK2AQyhh/l96ve5a388YHCczNwDnAFsDd6jT2QG4NXBVZl4w\nZFZn1ve7TKfkkiRJ0tq1nEfw/xq4O/DFzPy3Xved6vvlI8bruu+8yOElSZKkLdayBPyIeCnljjc/\nAg5ejnlIkiRJ2tzUA35EHAq8A/ghsH9mXjYwSHfEfSeG67p34y10+EnLOfK1bt26hUxKkiRJW6R1\nlEtBh71mZ+tpTiwiXgYcCfwAeERmXjRksB8De1HOmf9+v0c9b//2lItyzwbIzPURcT5wq4jYdch5\n+Heu75ud0z+Ot8mUJEnS0qyrr2FmF/KndgQ/Il5BCfffA/YbEe4BTqQs8QFD+u1Luaf9KZl53cA4\njBjnMfX9KwsutCRJktSYJT/oCiAiXgO8jvJgq0cNOS2nP2z/QVcPyczv1u7bUR509UDgoMw8tjdO\n96CrnwAP6KYfEXsA3wW2xwddSZKkGfBBVxpubT/J9hDgw5TTat7F8LvdnJuZf98b50DgWOBa4JPA\nJcDjKaftHJuZBw2Zz9uAlwPnA8cB2wJPA24GHJqZ752wvAZ8SZI0NQZ8Dbe2A/4RwGvnGexrmbnJ\ng6jqUflXA3sDN6Qcnf8gcHSOKFREHAy8GLgbsJFy9P6tmXn8AsprwJckSVNjwNdwazjgrzUGfEmS\nNE0GfA03u4C/nA+6kiRJkrTCDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIk\nSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJ\nUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElS\nQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJD\nDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM\n+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4\nkiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiS\nJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIk\nSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJ\nUkMM+JIkSVJDDPiSJElSQ6YS8CPiyRFxVEScHBGXR8TGiDhmxLC71/6jXv8wZj6HRMSpEXFlRFwW\nESdFxGOnsQySJElSC7ae0nQOB+4FXAX8HNhzgnFOAz47pPsPhw0cEW8D/gz4GfB+YFvgIOALEXFo\nZr5nEeWWJEmSmhKZufSJROwL/Dwzz6p/nwR8LDMPHjLs7sA5wEcy87kTTn9v4BTgTOD+mXlF7X47\n4HvADsCemXneBNNKgGkstyRJUkTUv8wW6iv1IjNjngGnbiqn6GTm1zLzrGlMa4QXUvaaN3Xhvs73\nPODdwHbAc5Zx/pIkSdKaMMuLbG8VEc+PiFfW93uOGXa/+n7CkH7HU74i7T/1EkqSJElrzLTOwV+M\nR9ZXJyLiq8AhmfmzXscdgFsDV2bmBUOmc2Z9v8tyFVSSJElaK2ZxBH898HpgL+Cm9bUvcCLwMODL\nEbF9b/id6vvlI6bXdd956iWVJEmS1pgVD/iZeWFmrsvM0zLzivr6BvAo4FTgTsDzVrpckiRJUgtW\nzYOuMnMD8HeU8+kf2uvVHaHfabORNu1+2TIVTZIkSVozVk3Ary6s7zt2HTJzPXA+cKOI2HXIOHeu\n72csZEYRMfK1bt26xZRdkiRJW5R1lGPTw16zM8uLbIfZu76fPdD9ROBZwAHA3w/0e0x9/8pCZuR9\n8CVJkrQ06+prmNmF/BU/gh8R94m5J0L0uz8ceBnlfvcfG+j9PspaenVE7NwbZw/gxcA1wEeWp8SS\nJEnS2jGVI/gRcSDwhPrvbvV9n4j4cP37osz8i/r3kcCdI+KbwM9rt3tR7mOfwOGZ+e3+9DPzWxFx\nJPBy4AcRcRywLfA0yt1zDp3kKbaSJElS62Iap6pExBHAa8cMcm5m3rEO+xzgicA9gF2AbYALgG8C\n787MU8bM52DKEfu7ARuB7wJvzczjF1DWBE/RkSRJ0zF3YoLZQn2lXmTmip+rM5WAv5YY8CVJ0jQZ\n8DXc7AL+aruLjiRJkqQlMOBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkN\nMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x\n4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHg\nS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBL\nkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuS\nJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5Ik\nSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJ\nDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkN\nMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x4EuSJEkNMeBLkiRJDTHgS5IkSQ0x\n4EuSJEkNMeBLkiRJDTHgS5IkSQ2ZSsCPiCdHxFERcXJEXB4RGyPimHnG2ScivhQRF0fE+og4PSIO\ni4iRZYqIQyLi1Ii4MiIui4iTIuKx01gGSZIkqQXTOoJ/OPBi4N7Az4EcN3BEHAh8DXgI8GngaGAb\n4O3AJ0aM8zbgw8BuwPuBjwL3AL4QES+aylJIkiRJa1xkjs3ik00kYl/g55l5Vv37JOBjmXnwkGFv\nDJwF3BjYJzO/X7tvW8d7EPD0zPzH3jh7A6cAZwL3z8wravfbAd8DdgD2zMzzJihrAkxjuSVJkiKi\n/mW2UF+pF5kZ8ww4dVM5gp+ZX8vMsyYc/KnALsAnunBfp/Ebyi8BAbxwYJwXUvaaN3Xhvo5zHvBu\nYDvgOYtfAkmSJKkNs7jIdj9KWD9hSL+TgfXAPhGxzcA4jBjneMqXgv2nWUhJkiRpLZpFwL9rfT9j\nsEdmbgDOAbYG7gAQETsAtwauyswLhkzvzPp+l+kXVZIkSVpbZhHwd6rvl4/o33XfeZHDS5IkSVss\n74MvSZIkNWQWAb874r7TiP5d98sWOfxEImLka926dQuZlCRJkrZI6yiXgg57zc7WM5jnj4G9KOfM\nf7/fIyK2Am4PXA+cDZCZ6yPifOBWEbHrkPPw71zfNzunfxxvkylJkqSlWVdfw8wu5M/iCP6JlCU+\nYEi/fSn3tD8lM68bGIcR4zymvn9laiWUJEmS1qhZBPzjgIuAgyJir65jRGwHvJFyC833DozzPsqX\ngldHxM69cfagPEH3GuAjy1loSZIkaS2Y1pNsDwSeUP/dDXgU5RSbr9duF2XmXwwMfyxwLfBJ4BLg\n8ZTTdo7NzIOGzONtwMuB8ylfErYFngbcDDg0Mwe/FIwqq0+ylSRJU+OTbDXc7J5kO62AfwTw2jGD\nnJuZdxwYZ2/g1cDewA2BnwAfBI7OEYWKiIMpR+zvBmwEvgu8NTOPX0BZDfiSJGlqDPgabo0H/LXE\ngC9JkqbJgK/hZhfwvQ++JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+\nJEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74k\nSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJ\nktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS\n1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLU\nEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQ\nA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BAD\nviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+\nJEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74kSZLUEAO+JEmS1BADviRJktQQA74k\nSZLUEAO+JEmS1BADviRJktSQmQX8iDg3IjaOeP1ixDj7RMSXIuLiiFgfEadHxGER4RcVSZIkCdh6\nhvNO4DLg7UAM9LtqcOCIOBA4Dvg18CngEuBxdfx9gKctZ2ElSZKktSAyczYzjjgHyMy8wwTD3hg4\nC7gxsE9mfr923xY4CXgQ8PTM/McJppWUGS+h9JIkSUVEd5zSbKG+Ui8yc/BA9rJbK6e2PBXYBfhE\nF+4BMvM3wOGUNfjCGZVNkiRJWjVmeYoOwHYR8UzgdsDVwA+AkzNz48Bw+1G+Fp8wZBonA+uBfSJi\nm8y8bjkLLEmSJK1msw74uwHH9P4P4JyIeE5mntzrftf6fsbgBDJzQz3d527AHYAfL1dhJUmSpNVu\nlqfofAh4OCXk7wjcE3gfsAfwpYi4Z2/Yner75SOm1XXfefrFlCRJktaOmR3Bz8w3DHT6EfCiiLga\n+HNgHfDklS6XJEmStJatxots31ffH9rr1h2h34nhuu6XTTqTiBj5Wrdu3cJKLEmSpC3QOsoZ5sNe\nszOz22SOEhE3oQT1azJzh9rto8AzgGdk5qcGht+K8gVgG+BG811k620yJUnSNHmbTA3nbTL79q7v\nZ/e6nUhZSwcMGX5fYAfgFO+gI0mSpC3dTAJ+ROwZETsM6b4H8C7KV+CP9nodB1wEHBQRe/WG3w54\nYx3+vctYZEmSJGlNmMkpOhFxBOVC2pOBnwJXAncEHgtsB3wReFJmXt8b50DgWOBa4JPAJcDjgbsA\nx2bmQRPO21N0JEnS1HiKjoab3Sk6swr4DwVeANyHudtkXgacBhyTmR8fMd7ewKspp/HcEPgJ8EHg\n6JxwQQz4kiRpmgz4Gm4LC/izZMCXJEnTZMDXcF5kK0mSJGkKDPiSJElSQwz4kiRJUkMM+JIkSVJD\nDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM\n+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4\nkiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiS\nJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIk\nSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJ\nUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElS\nQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJDDPiSJElSQwz4kiRJUkMM+JIkSVJD\ntp51AWbl6quvnnURtMpsvfXWbLfddrMuhiRJ0pJEZs66DCsqIrasBdbEXvKSl3DUUUfNuhiSpDUm\nIupfRgz1lXqRmTHPgFO3xR7Bhx1mXQCtGtfVlyRJ0tq3BQd8T9FR5yjgsFkXQpIkaSq8yFaSJElq\niAFfkiRJaogBX5IkSWqIAV+SJElqiAFfkiRJaogBX5IkSWqIAV+SJElqiAFfkiRJaogBX5IkSWrI\nmgr4EXHriPhQRJwfEddExDkR8faI2HnWZZMkSZJWgzUT8CPiDsD3gEOAbwNHAmcBhwHfjIibzrB4\n0lSsW7du1kWQhrJuajWzfkqbisycdRkmEhEnAI8AXpKZ7+l1/1vg5cD7MvNFE0ynLvDaWG6thKOA\nw3jJS17CUUcdNdOSRARrZZ/UlsW6qdVs1vUzIupf7iPqK/UiM2OeAaduTRzBr0fvHwmc2w/31RHA\n1cAfR8T2K144SZIkaRVZEwEf2K++/+tgj8y8CjgF2AF40EoWSpIkSVpt1krAvyvld68zRvQ/s77f\nZWWKI0mSJK1OayXg71TfLx/Rv+vu3XQkSZK0Rdt61gWYnffPugBaNU6ZdQEkSZKmZq0E/O4I/U4j\n+nfdL5t8ki9YQnHUoqOPPpqjjz561sXo3Y1BWl2sm1rNVkf9XA1lkNbOKTo/puw1o86xv3N9H3WO\nviRJkrRFWBP3wa+3yfwJcE5m3nGg342AX9Z/b5GZv17p8kmSJEmrxZo4gp+ZZ1NukblHRBw60Pv1\nwI7AMYZ7SZIkbenWxBF8+O1R/FOAWwCfB/6bct/7hwH/Azw4My+dWQElSZKkVWDNBHyAiLg15Yj9\nAcDNKafmfBp4fWaOuoWmJEmStMVYUwFfkiRJ0nhr4hx8SZIkSZMx4EuSJEkNMeBLkiRJDWk24EfE\n1hFxWER8KCK+HxHXRsTGiHjuEqa5T0R8KSIujoj1EXF6nUez61HLZxr1KSJ2r/V61OsflnMZtHZF\nxK1r+3h+RFwTEedExNsjYudZTEfqTKNORcS5Y9rFXyxn+dWuiHhyRBwVESdHxOW1Ph2zyGkta9u5\n9TQmskrtCLwdSOACyh13brvYiUXEgcBxwK+BTwGXAI+r89gHeNoSy6styDLUp9OAzw7p/sMlFFON\nqrcd/hawC6Xe/Bh4AHAY8KiImOi2w9OajtSZYp1K4DJKmxoD/a6aXom1hTkcuBelDv0c2HMxE1mR\ntjMzm3wB2wCPAnat/x8BbACeu4hp3Rj4FSWM3afXfVvKvfk3AH8062X2tTZe06xPwO7ARuBDs14u\nX2vnBZxQ69mLBrr/ba1P71nJ6fjy1b2mWDfPAc6e9fL4ausF7Avcsff3RsqDVhc6nWVvO5s9tSQz\nr8vMEzLzgilM7qmUb1mfyMzv9+bxG8q3uQBeOIX5aMtgfdLM1CNHjwTOzcz3DPQ+Arga+OOI2H4l\npiN1rFNa7TLza5l51lKmsVL1vNmAP2X7UX7uO2FIv5OB9cA+EbHNipZKa9Vy1KdbRcTzI+KV9f2e\n0yiomrRfff/XwR6ZeRXlV6QdKE8KX4npSJ1p16ntIuKZtV18aUQ8zGvmtAqsSNtpRZ/MXev7GYM9\nMnMD5afArYE7rGShtGYtR316JPBe4I31/fSIODEiFn3diZp1V8oXzM3qX3Vmfb/LCk1H6ky7Tu0G\nHENpF98OnAicGREPXUohpSVakbbTgD+Zner75SP6d929a4QmMc36tB54PbAXcNP62pfyQfYw4Mv+\nnK0B06p/touatmnWqQ8BD6eE/B2BewLvA/YAvuSvnJqhFWk7V3XAn+c2V8Nei7pVkbRQq6VuZuaF\nmbkuM0/LzCvq6xuUC8xPBe4EPG855i1Jq1VmviEzv1rbyGsy80eZ+SLgSMrpD+tmW0Jpea3222Se\nSTlCOanzl6kc3bepnUb077pftkzz1+qz0LrZv+/ystenzNwQEX8HPBB4KHD0Yqel5kyr/tkuatpW\nok69D/hzSrsozcKKtJ2rOuBn5iNnXYbqx5RTIO4CfL/fIyK2Am4PXA+cvfJF0ywssW6uVH26sL7v\nuMTpqC0/ptypadT5nXeu76POD532dKTOStQp20XN2oq0nav6FJ1V5ETKxjhgSL99KT/3nZKZ161o\nqbRWrVR92ru++8VTfSfV9z8Y7BERNwIeTPl16tsrNB2psxJ1ynZRs7YibacBvycibhIRd42I3QZ6\nHQdcBBwUEXv1ht+OcnV+Uu5cIk1iwfVpVN2MiPtExOBTGomIhwMvq9P62PQXQWtVZp5NuT3bHhFx\n6EDv11OObB6Tmb8GiIita927w1KmI81nWnUzIvaMiB0Gpx8RewDvorSLH53+EkhzZt12Rn1yVpMi\n4hXMPUb494B7A99k7hZE38jMD/aGPwT4MPCRzHzuwLQOBI4FrgU+CVwCPJ7yE8uxmXnQMi6KGrPQ\n+jSqbkbESZSf875JeWw2lMdo70/5EDs8M9+8vEujtaZ+4JwC3AL4PPDflHsuPwz4H+C3j0mPiN0p\nt249NzMHg9TE05EmMY26GRFHUM6zPxn4KXAlcEfgscB2wBeBJ2Xm9SuzVGpF/ex+Qv13N8oNLc4G\nvl67XZSZf1GHnWnbuarPwZ+CA9j0Qpqk/Dy3d+//Dw6Mk/W1acfMz0XEvsCrgScBNwR+ArwcL2DU\nAi2yPg2rm8cATwTuR6nv2wAXUL40vDszT5l+6bXWZebZEXE/ytGiA4BHA7+k3Cv89Zk5ePu2Ue3i\nQqcjjTWlunkS5WDJfYB9KEdEL6OEsGMy8+PLtwRq3O8BB/f+T8p1c7ev/58L/MVA/5m0nU0fwZck\nSZK2NJ6DL0mSJDXEgC9JkiQ1xIAvSZIkNcSAL0mSJDXEgC9JkiQ1xIAvSZIkNcSAL0mSJDXEgC9J\nkiQ1xIAvSZIkNcSAL0mSJDXEgC9JkiQ1xIAvSZIkNcSAL0mSJDXEgC9JkiQ1xIAvSZIkNcSAL0mS\nJDXEgC9JkiQ15P8HWQvewMlrsiEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106b67910>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 265,
       "width": 380
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "# let's take a look at the types of labels  are present in the data.\n",
    "# The ones correspond to label 1 and 7's(outliers) correspond to label -1\n",
    "#data.label.value_counts().plot(kind='bar')  \n",
    "type(Xlabels)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(Xlabels,bins=5)\n",
    "plt.title(\"Count of Normal and Anomalous datapoints in training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAKING OUR DATA ONE-CLASS\n",
    "\n",
    "Later we're going to use scikit-learn's OneClassSVM predict function to generate output. This returns +1 or -1 to indicate whether the data is an \"inlier\" or \"outlier\" respectively. To make comparison easier later we'll replace our data's label with a matching +1 or -1 value. This also transforms our data from multi-class (multiple different labels) to one-class (boolean label), which is a prerequisite for using a one-class SVM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('outliers.shape', (11,))\n",
      "('outlier fraction', 0.047619047619047616)\n",
      "Training data shape... (231, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# series, not a new dataframe\n",
    "target = Xlabels\n",
    "# find the proportion of outliers we expect (aka where `labels == -1`). because \n",
    "# target is a series, we just compare against itself rather than a column.\n",
    "outliers = target[target == -1]  \n",
    "print(\"outliers.shape\", outliers.shape)  \n",
    "print(\"outlier fraction\", float(outliers.shape[0])/target.shape[0])\n",
    "\n",
    "# Print the shape of the input data for sanity\n",
    "print \"Training data shape...\",data.shape\n",
    "# temp =  data[0:180]\n",
    "# print temp.shape\n",
    "# print data[1]\n",
    "# data = data[0:220]\n",
    "# target = target[0:220]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPLITTING DATA INTO TRAINING AND TEST SETS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split\n",
    "# train_data, test_data, train_target, test_target = train_test_split(data, target, train_size = 0.8)  \n",
    "# train_data.shape  \n",
    "\n",
    "\n",
    "# # We learn the digits on the first half of the digits\n",
    "# data_train, targets_train = train_data,train_target\n",
    "\n",
    "# # Now predict the value of the digit on the second half:\n",
    "# data_test, targets_test = test_data,test_target\n",
    "\n",
    "data_train = data[0:219]\n",
    "targets_train = target[0:219]\n",
    "data_test = data[220:231]\n",
    "targets_test = target[220:231]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING THE MODELS: OneClass SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nu', 0.047619047619047616)\n",
      "One Class SVM output: for negative values are\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import svm\n",
    "\n",
    "# set nu (which should be the proportion of outliers in our dataset)\n",
    "nu = float(outliers.shape[0]) / target.shape[0]  \n",
    "print(\"nu\", nu)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, pipeline\n",
    "from sklearn.kernel_approximation import (RBFSampler,\n",
    "                                          Nystroem)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics \n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "kernel_svm = svm.SVC(gamma=.2)\n",
    "linear_svm = svm.LinearSVC()\n",
    "oneClass_svm = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=0.00005)\n",
    "oneClass_svm_time = time()\n",
    "oneClass_svm.fit(data_train) \n",
    "preds = oneClass_svm.predict(data_test)  \n",
    "print \"One Class SVM output: for negative values are\"\n",
    "print preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Single Hidden Layer : One ClassNeural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.00105\u001b[0m\u001b[0m | time: 0.020s\n",
      "| SGD | epoch: 200 | loss: 0.00105 - binary_acc: 1.0000 -- iter: 192/219\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.00105\u001b[0m\u001b[0m | time: 0.026s\n",
      "| SGD | epoch: 200 | loss: 0.00105 - binary_acc: 1.0000 -- iter: 219/219\n",
      "--\n",
      "Training Pridicted output:\n",
      "[[  2.09982048e-07]\n",
      " [  2.13689248e-07]\n",
      " [  2.05036258e-07]\n",
      " [  2.07125211e-07]\n",
      " [  2.29722588e-07]\n",
      " [  2.12234085e-07]\n",
      " [  2.06689720e-07]\n",
      " [  2.07003765e-07]\n",
      " [  2.15179867e-07]\n",
      " [  2.07955310e-07]\n",
      " [  2.06024524e-07]\n",
      " [  2.10179394e-07]\n",
      " [  2.13078778e-07]\n",
      " [  2.10450352e-07]\n",
      " [  2.29579342e-07]\n",
      " [  2.23694911e-07]\n",
      " [  2.06763445e-07]\n",
      " [  2.32623847e-07]\n",
      " [  2.07326778e-07]\n",
      " [  2.13661124e-07]\n",
      " [  2.08935134e-07]\n",
      " [  2.07603179e-07]\n",
      " [  2.08362067e-07]\n",
      " [  2.08539788e-07]\n",
      " [  2.06335216e-07]\n",
      " [  2.04963925e-07]\n",
      " [  2.07392631e-07]\n",
      " [  2.17709498e-07]\n",
      " [  2.31573580e-07]\n",
      " [  2.13478629e-07]\n",
      " [  2.08003911e-07]\n",
      " [  2.07675072e-07]\n",
      " [  2.15510084e-07]\n",
      " [  2.06920859e-07]\n",
      " [  2.09353189e-07]\n",
      " [  2.06801104e-07]\n",
      " [  2.10592304e-07]\n",
      " [  2.09432656e-07]\n",
      " [  2.13567020e-07]\n",
      " [  2.08694374e-07]\n",
      " [  2.06227412e-07]\n",
      " [  2.13195023e-07]\n",
      " [  2.08829960e-07]\n",
      " [  2.07271242e-07]\n",
      " [  2.20362750e-07]\n",
      " [  2.13569066e-07]\n",
      " [  2.09955417e-07]\n",
      " [  2.17292154e-07]\n",
      " [  2.06209904e-07]\n",
      " [  2.14231207e-07]\n",
      " [  2.20317574e-07]\n",
      " [  2.25523962e-07]\n",
      " [  2.06483634e-07]\n",
      " [  2.11075260e-07]\n",
      " [  2.14423750e-07]\n",
      " [  2.22572822e-07]\n",
      " [  2.06315931e-07]\n",
      " [  2.21326104e-07]\n",
      " [  2.12211404e-07]\n",
      " [  2.32678431e-07]\n",
      " [  2.08446721e-07]\n",
      " [  2.15351690e-07]\n",
      " [  2.06525783e-07]\n",
      " [  2.15946457e-07]\n",
      " [  2.09263362e-07]\n",
      " [  2.11890892e-07]\n",
      " [  2.10656793e-07]\n",
      " [  2.05791636e-07]\n",
      " [  2.24674096e-07]\n",
      " [  2.08061039e-07]\n",
      " [  2.13615309e-07]\n",
      " [  2.05758866e-07]\n",
      " [  2.12692214e-07]\n",
      " [  2.08320529e-07]\n",
      " [  2.12558376e-07]\n",
      " [  2.09057916e-07]\n",
      " [  2.36132834e-07]\n",
      " [  2.12418541e-07]\n",
      " [  2.15295003e-07]\n",
      " [  2.32301957e-07]\n",
      " [  2.06428112e-07]\n",
      " [  2.05473569e-07]\n",
      " [  2.04588972e-07]\n",
      " [  2.05907085e-07]\n",
      " [  2.04672887e-07]\n",
      " [  2.09206291e-07]\n",
      " [  2.18590131e-07]\n",
      " [  2.04304882e-07]\n",
      " [  2.05465341e-07]\n",
      " [  2.13914774e-07]\n",
      " [  2.10077587e-07]\n",
      " [  2.14706361e-07]\n",
      " [  2.11513949e-07]\n",
      " [  2.09704865e-07]\n",
      " [  2.16583359e-07]\n",
      " [  2.24733014e-07]\n",
      " [  2.07589736e-07]\n",
      " [  2.17921155e-07]\n",
      " [  2.30672498e-07]\n",
      " [  2.04693578e-07]\n",
      " [  2.10543718e-07]\n",
      " [  2.07328767e-07]\n",
      " [  2.14332985e-07]\n",
      " [  2.16771170e-07]\n",
      " [  2.09193118e-07]\n",
      " [  2.07252256e-07]\n",
      " [  2.05664108e-07]\n",
      " [  2.08809439e-07]\n",
      " [  2.32616316e-07]\n",
      " [  2.25946579e-07]\n",
      " [  2.08591516e-07]\n",
      " [  3.17891789e-07]\n",
      " [  2.15328683e-07]\n",
      " [  2.20152501e-07]\n",
      " [  2.07884909e-07]\n",
      " [  2.08567627e-07]\n",
      " [  2.13639126e-07]\n",
      " [  2.30395713e-07]\n",
      " [  2.06999218e-07]\n",
      " [  2.45376384e-07]\n",
      " [  2.15257245e-07]\n",
      " [  2.08167620e-07]\n",
      " [  2.05035278e-07]\n",
      " [  2.29714701e-07]\n",
      " [  2.75407473e-07]\n",
      " [  2.15524281e-07]\n",
      " [  2.06885133e-07]\n",
      " [  2.06603204e-07]\n",
      " [  2.17839087e-07]\n",
      " [  2.07630691e-07]\n",
      " [  2.06549032e-07]\n",
      " [  2.09849119e-07]\n",
      " [  2.07584577e-07]\n",
      " [  2.09808292e-07]\n",
      " [  2.35740643e-07]\n",
      " [  2.14889482e-07]\n",
      " [  2.12410853e-07]\n",
      " [  2.06158788e-07]\n",
      " [  2.08120184e-07]\n",
      " [  2.09995861e-07]\n",
      " [  2.13430610e-07]\n",
      " [  2.07827625e-07]\n",
      " [  2.11701007e-07]\n",
      " [  2.13075097e-07]\n",
      " [  2.13294271e-07]\n",
      " [  2.17368836e-07]\n",
      " [  2.15146827e-07]\n",
      " [  2.17758895e-07]\n",
      " [  2.11671747e-07]\n",
      " [  2.21094055e-07]\n",
      " [  2.05511384e-07]\n",
      " [  2.12823892e-07]\n",
      " [  2.10262186e-07]\n",
      " [  2.23103683e-07]\n",
      " [  2.16500951e-07]\n",
      " [  2.11749267e-07]\n",
      " [  2.13625896e-07]\n",
      " [  2.09596919e-07]\n",
      " [  2.13337003e-07]\n",
      " [  2.11819753e-07]\n",
      " [  2.07779067e-07]\n",
      " [  2.06755956e-07]\n",
      " [  2.07374825e-07]\n",
      " [  2.09456232e-07]\n",
      " [  2.16163642e-07]\n",
      " [  2.16557325e-07]\n",
      " [  2.24730471e-07]\n",
      " [  2.28931100e-07]\n",
      " [  2.06776079e-07]\n",
      " [  2.35530763e-07]\n",
      " [  2.08392080e-07]\n",
      " [  2.10324160e-07]\n",
      " [  2.07245535e-07]\n",
      " [  2.15976513e-07]\n",
      " [  2.04652594e-07]\n",
      " [  2.10596923e-07]\n",
      " [  2.36308324e-07]\n",
      " [  2.09513175e-07]\n",
      " [  2.04127858e-07]\n",
      " [  2.10160948e-07]\n",
      " [  2.10905029e-07]\n",
      " [  2.07431398e-07]\n",
      " [  2.09197324e-07]\n",
      " [  2.29663229e-07]\n",
      " [  2.25519898e-07]\n",
      " [  2.08298090e-07]\n",
      " [  2.11109295e-07]\n",
      " [  2.07688714e-07]\n",
      " [  2.10562575e-07]\n",
      " [  2.14072315e-07]\n",
      " [  2.08638639e-07]\n",
      " [  2.08512347e-07]\n",
      " [  2.09028002e-07]\n",
      " [  2.13295905e-07]\n",
      " [  2.11653173e-07]\n",
      " [  2.09446057e-07]\n",
      " [  2.06828332e-07]\n",
      " [  2.06418463e-07]\n",
      " [  2.05171617e-07]\n",
      " [  2.25711389e-07]\n",
      " [  2.07430219e-07]\n",
      " [  2.06736232e-07]\n",
      " [  2.12007507e-07]\n",
      " [  2.11710315e-07]\n",
      " [  2.16096652e-07]\n",
      " [  2.07446050e-07]\n",
      " [  2.06034358e-07]\n",
      " [  2.05102751e-07]\n",
      " [  2.09116934e-07]\n",
      " [  2.06186883e-07]\n",
      " [  2.10155932e-07]\n",
      " [  2.30226377e-07]\n",
      " [  2.05548830e-07]\n",
      " [  2.07450583e-07]\n",
      " [  2.36305169e-07]\n",
      " [  2.47388869e-07]\n",
      " [  2.12577447e-07]\n",
      " [  2.08456669e-07]\n",
      " [  2.09500996e-07]]\n",
      "Test Pridicted output:\n",
      "[[  3.74926145e-07]\n",
      " [  5.20678270e-07]\n",
      " [  3.13092272e-07]\n",
      " [  3.29897574e-07]\n",
      " [  4.08898728e-07]\n",
      " [  3.31229813e-07]\n",
      " [  3.50876519e-07]\n",
      " [  3.39031345e-07]\n",
      " [  3.70422441e-07]\n",
      " [  3.82656111e-07]\n",
      " [  4.32933035e-07]]\n"
     ]
    }
   ],
   "source": [
    "from tflearn import DNN\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression,oneClassNN\n",
    "from tflearn.metrics import binary_accuracy_op\n",
    "from time import time\n",
    "from sklearn import metrics \n",
    "import tensorflow as tf\n",
    "\n",
    "# Clear all the graph variables created in previous run and start fresh\n",
    "tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()\n",
    "#Training examples\n",
    "X = data_train\n",
    "# Y = [[0], [0], [0], [0]]\n",
    "Y = targets_train\n",
    "# Y = list(Y)\n",
    "Y = Y.tolist()\n",
    "Y= [[i] for i in Y]\n",
    "\n",
    "# For testing the algorithm\n",
    "X_test = data_test\n",
    "Y_test = targets_test\n",
    "Y_test= Y_test.tolist()\n",
    "Y_test= [[i] for i in Y_test]\n",
    "\n",
    "m,n = data_train.shape\n",
    "No_of_inputNodes = n\n",
    "No_of_hiddenNodes=n\n",
    "print \"No_of_hiddenNodes\",No_of_hiddenNodes\n",
    "\n",
    "input_layer = input_data(shape=[None, No_of_inputNodes]) #input layer of size 2\n",
    "hidden_layer = fully_connected(input_layer , No_of_hiddenNodes, activation='sigmoid',name=\"hiddenLayer_Weights\") #hidden layer of size 2\n",
    "output_layer = fully_connected(hidden_layer, 1, activation='sigmoid',name=\"outputLayer_Weights\") #output layer of size 1\n",
    "\n",
    "# Hyper parameters for the one class Neural Network\n",
    "v = 0.04\n",
    "import tflearn.variables as va\n",
    "# rho = va.variable(name='rho', shape=[])\n",
    "rho=0.3\n",
    "#use Stohastic Gradient Descent and Binary Crossentropy as loss function\n",
    "oneClassNN = oneClassNN(output_layer,v,rho,hidden_layer,output_layer,optimizer='sgd', loss='OneClassNN_Loss', learning_rate=5)\n",
    "model = DNN(oneClassNN,tensorboard_verbose=3)\n",
    "#fit the model\n",
    "model.fit(X, Y, n_epoch=200, show_metric=True);\n",
    "data_train = data[0:219]\n",
    "y_pred = model.predict(data_train) # Apply some ops\n",
    "\n",
    "# Define the Iteration for optimising and stabilizing the value of r\n",
    "iterStep = 0\n",
    "# sess = tf.Session()\n",
    "# sess.run(init)\n",
    "import numpy as np\n",
    "rho_previous = rho\n",
    "rho_next = 0\n",
    "# Loop till the value of rho stabilizes\n",
    "while ((rho_previous - rho_next) <= 0.00001):\n",
    "    print \"Running Iteration :\",iterStep\n",
    "    yHat = model.predict(data_train) # Apply some ops\n",
    "    y_pred = np.sort(-y_pred)\n",
    "    rhoIndex = int(v * len(data_train))\n",
    "    rho=(y_pred[rhoIndex] + y_pred[rhoIndex+1])/2\n",
    "    rho_next =rho \n",
    "    model.fit(X, Y, n_epoch=200, show_metric=True)\n",
    "    iterStep = iterStep + 1\n",
    "\n",
    "#The data_train and data_test \n",
    "data_train = data[0:219]\n",
    "y_pred = model.predict(data_train) # Apply some ops\n",
    "print \"Training Pridicted output:\"\n",
    "print y_pred\n",
    "\n",
    "data_test = data[220:231]\n",
    "y_pred = model.predict(data_test)\n",
    "print \"Test Pridicted output:\"\n",
    "print y_pred\n",
    "\n",
    "# if(tf.reduce_mean() == v):\n",
    "#     #Stop the optimization\n",
    "# else:\n",
    "#     rho=(1/v)*y_pred\n",
    "#     #use Stohastic Gradient Descent and Binary Crossentropy as loss function\n",
    "#     oneClassNN = oneClassNN(output_layer,v,rho,hidden_layer,output_layer,optimizer='sgd', loss='OneClassNN_Loss', learning_rate=5)\n",
    "#     model = DNN(oneClassNN,tensorboard_verbose=3)\n",
    "#     #fit the model\n",
    "#     model.fit(X, Y, n_epoch=200, show_metric=True)\n",
    "#     y_pred = model.predict(data_train) # Apply some ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pridicted output:\n",
      "[[ 0.99995577]\n",
      " [ 0.99995553]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995482]\n",
      " [ 0.99995565]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995565]\n",
      " [ 0.99995553]\n",
      " [ 0.99995565]\n",
      " [ 0.99995482]\n",
      " [ 0.99995506]\n",
      " [ 0.99995589]\n",
      " [ 0.9999547 ]\n",
      " [ 0.99995577]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995577]\n",
      " [ 0.99995542]\n",
      " [ 0.99995482]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995542]\n",
      " [ 0.99995589]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.9999553 ]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995542]\n",
      " [ 0.99995589]\n",
      " [ 0.99995553]\n",
      " [ 0.9999553 ]\n",
      " [ 0.99995506]\n",
      " [ 0.99995589]\n",
      " [ 0.99995565]\n",
      " [ 0.99995553]\n",
      " [ 0.99995518]\n",
      " [ 0.99995589]\n",
      " [ 0.99995518]\n",
      " [ 0.99995565]\n",
      " [ 0.9999547 ]\n",
      " [ 0.99995577]\n",
      " [ 0.99995542]\n",
      " [ 0.99995589]\n",
      " [ 0.99995542]\n",
      " [ 0.99995577]\n",
      " [ 0.99995565]\n",
      " [ 0.99995565]\n",
      " [ 0.99995589]\n",
      " [ 0.99995506]\n",
      " [ 0.99995577]\n",
      " [ 0.99995553]\n",
      " [ 0.99995589]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995458]\n",
      " [ 0.99995565]\n",
      " [ 0.99995542]\n",
      " [ 0.9999547 ]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995601]\n",
      " [ 0.99995589]\n",
      " [ 0.99995601]\n",
      " [ 0.99995577]\n",
      " [ 0.9999553 ]\n",
      " [ 0.99995601]\n",
      " [ 0.99995589]\n",
      " [ 0.99995553]\n",
      " [ 0.99995565]\n",
      " [ 0.99995553]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995542]\n",
      " [ 0.99995506]\n",
      " [ 0.99995577]\n",
      " [ 0.99995542]\n",
      " [ 0.99995482]\n",
      " [ 0.99995601]\n",
      " [ 0.99995565]\n",
      " [ 0.99995589]\n",
      " [ 0.99995553]\n",
      " [ 0.99995542]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995577]\n",
      " [ 0.9999547 ]\n",
      " [ 0.99995506]\n",
      " [ 0.99995577]\n",
      " [ 0.99995172]\n",
      " [ 0.99995542]\n",
      " [ 0.9999553 ]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995553]\n",
      " [ 0.99995482]\n",
      " [ 0.99995589]\n",
      " [ 0.99995422]\n",
      " [ 0.99995542]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995482]\n",
      " [ 0.99995315]\n",
      " [ 0.99995542]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995542]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995458]\n",
      " [ 0.99995553]\n",
      " [ 0.99995565]\n",
      " [ 0.99995589]\n",
      " [ 0.99995577]\n",
      " [ 0.99995565]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995565]\n",
      " [ 0.99995553]\n",
      " [ 0.99995553]\n",
      " [ 0.99995542]\n",
      " [ 0.99995553]\n",
      " [ 0.99995542]\n",
      " [ 0.99995565]\n",
      " [ 0.99995518]\n",
      " [ 0.99995589]\n",
      " [ 0.99995553]\n",
      " [ 0.99995565]\n",
      " [ 0.99995518]\n",
      " [ 0.99995542]\n",
      " [ 0.99995565]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995553]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995542]\n",
      " [ 0.99995542]\n",
      " [ 0.99995506]\n",
      " [ 0.99995494]\n",
      " [ 0.99995589]\n",
      " [ 0.99995458]\n",
      " [ 0.99995577]\n",
      " [ 0.99995565]\n",
      " [ 0.99995589]\n",
      " [ 0.99995542]\n",
      " [ 0.99995601]\n",
      " [ 0.99995565]\n",
      " [ 0.99995458]\n",
      " [ 0.99995577]\n",
      " [ 0.99995601]\n",
      " [ 0.99995565]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995482]\n",
      " [ 0.99995506]\n",
      " [ 0.99995577]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995565]\n",
      " [ 0.99995553]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]\n",
      " [ 0.99995553]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995506]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995565]\n",
      " [ 0.99995565]\n",
      " [ 0.99995542]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995577]\n",
      " [ 0.99995589]\n",
      " [ 0.99995565]\n",
      " [ 0.99995482]\n",
      " [ 0.99995589]\n",
      " [ 0.99995589]\n",
      " [ 0.99995458]\n",
      " [ 0.9999541 ]\n",
      " [ 0.99995565]\n",
      " [ 0.99995577]\n",
      " [ 0.99995577]]\n",
      "Test Pridicted output:\n",
      "[[ 0.99995017]\n",
      " [ 0.99994671]\n",
      " [ 0.99995196]\n",
      " [ 0.99995136]\n",
      " [ 0.99994922]\n",
      " [ 0.99995136]\n",
      " [ 0.99995077]\n",
      " [ 0.99995112]\n",
      " [ 0.99995029]\n",
      " [ 0.99994993]\n",
      " [ 0.99994862]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# # y_pred = model.predict(data_test)\n",
    "# oneClass_nn_time = time() \n",
    "# preds = model.predict(X_test)\n",
    "# targs = targets_test\n",
    "\n",
    "# oneClass_nn_score = metrics.accuracy_score(targs, preds.round())  \n",
    "# # Compute the AUC for OneClassNN\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(targs, preds)\n",
    "# oneClass_nn_auc_score = metrics.auc(fpr, tpr)\n",
    "# # oneClass_nn_score = metrics.accuracy_score(targs, np.ones((len(targs),)))  \n",
    "# oneClass_nn_time = time() - oneClass_nn_time\n",
    "# print \"OneClassNN- Classifier Accuracy\",oneClass_nn_score,oneClass_nn_time\n",
    "# print \"OneClassNN- Classifier AUC:\",oneClass_nn_auc_score,oneClass_nn_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING THE MODELS: OneClass SVM, LINEAR KERNEL with Random Fourier Features, RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nu', 0.047619047619047616)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-773a834c9d17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mkernel_svm_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mkernel_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mkernel_svm_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_svm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/raghav/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[0;32m/Users/raghav/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    519\u001b[0m             raise ValueError(\n\u001b[1;32m    520\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 % len(cls))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# set nu (which should be the proportion of outliers in our dataset)\n",
    "nu = float(outliers.shape[0]) / target.shape[0]  \n",
    "print(\"nu\", nu)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, pipeline\n",
    "from sklearn.kernel_approximation import (RBFSampler,\n",
    "                                          Nystroem)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics \n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "kernel_svm = svm.SVC(gamma=.2)\n",
    "linear_svm = svm.LinearSVC()\n",
    "oneClass_svm = svm.OneClassSVM(nu=nu, kernel='rbf', gamma=0.00005)  \n",
    "# oneClass_svm = svm.OneClassSVM(nu=nu, kernel='linear', gamma=0.00005)\n",
    "# create pipeline from kernel approximation\n",
    "# and linear svm\n",
    "feature_map_fourier = RBFSampler(gamma=.2, random_state=1)\n",
    "fourier_approx_svm = pipeline.Pipeline([(\"feature_map\", feature_map_fourier),\n",
    "                                        (\"svm\", svm.LinearSVC())])\n",
    "\n",
    "OneClass_svm_Linear_fourier = pipeline.Pipeline([(\"feature_map\", feature_map_fourier),\n",
    "                                          (\"svm\", svm.OneClassSVM(nu=nu, kernel='linear', gamma=0.00005))])\n",
    "\n",
    "# fit and predict using linear and kernel svm:\n",
    "\n",
    "kernel_svm_time = time()\n",
    "kernel_svm.fit(data_train, targets_train)\n",
    "\n",
    "kernel_svm_score = kernel_svm.score(data_test, targets_test)\n",
    "kernel_svm_time = time() - kernel_svm_time\n",
    "\n",
    "## Compute AUC for the Linear SVM classifier performance\n",
    "preds = kernel_svm.predict(data_test)  \n",
    "targs = targets_test\n",
    "fpr, tpr, thresholds = metrics.roc_curve(targs, preds)\n",
    "kernel_svm_auc_score = metrics.auc(fpr, tpr)\n",
    "kernel_svm_time = time() - kernel_svm_time\n",
    "print \"kernel_svm Classifier AUC:\",kernel_svm_auc_score,kernel_svm_time\n",
    "\n",
    "print \"Kernel SVM-Targets and predicted..\"\n",
    "print targs\n",
    "print preds\n",
    "\n",
    "linear_svm_time = time()\n",
    "linear_svm.fit(data_train, targets_train)\n",
    "linear_svm_score = linear_svm.score(data_test, targets_test)\n",
    "preds = linear_svm.predict(data_train)  \n",
    "targs = targets_train\n",
    "\n",
    "## Compute AUC for the Linear SVM classifier performance\n",
    "preds = linear_svm.predict(data_train)  \n",
    "targs = targets_train\n",
    "fpr, tpr, thresholds = metrics.roc_curve(targs, preds)\n",
    "linear_svm_auc_score = metrics.auc(fpr, tpr)\n",
    "linear_svm_time = time() - linear_svm_time\n",
    "# print \"linear_svm Classifier AUC:\",linear_svm_auc_score,linear_svm_time\n",
    "\n",
    "\n",
    "oneClass_svm_time = time()\n",
    "oneClass_svm.fit(data_train) \n",
    "preds = oneClass_svm.predict(data_test)  \n",
    "targs = targets_test\n",
    "oneClass_svm_score = metrics.accuracy_score(targs, preds)  \n",
    "oneClass_svm_time = time() - oneClass_svm_time\n",
    "\n",
    "print \"oneClass_svm and predicted..\"\n",
    "print targs\n",
    "print preds\n",
    "\n",
    "# Compute the AUC for oneClass_svm\n",
    "fpr, tpr, thresholds = metrics.roc_curve(targs, preds)\n",
    "oneClass_svm_auc_score = metrics.auc(fpr, tpr)\n",
    "print \"oneClass_svm Classifier AUC:\",oneClass_svm_auc_score,oneClass_svm_time\n",
    "\n",
    "## Use Sampling for RFF method \n",
    "sample_sizes = 30 * np.arange(1, 10)\n",
    "fourier_scores = []\n",
    "fourier_times = []\n",
    "fourier_auc_scores= []\n",
    "\n",
    "for D in sample_sizes:\n",
    "    fourier_approx_svm.set_params(feature_map__n_components=D)\n",
    "    start = time()\n",
    "    fourier_approx_svm.fit(data_train, targets_train)\n",
    "    fourier_times.append(time() - start)\n",
    "\n",
    "    fourier_score = fourier_approx_svm.score(data_test, targets_test)\n",
    "    fourier_scores.append(fourier_score)\n",
    "    \n",
    "    ## Compute AUC for the FF  classifier performance\n",
    "    preds = fourier_approx_svm.predict(data_test)  \n",
    "    targs = targets_test\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(targs, preds)\n",
    "    fourier_approx_auc_score = metrics.auc(fpr, tpr)\n",
    "    fourier_auc_scores.append(fourier_approx_auc_score)\n",
    "#     print \"fourier_approx_svm Classifier AUC:\",fourier_approx_auc_score,fourier_times\n",
    "\n",
    "\n",
    "## Use Sampling for OneClassSVM + Linear Kerner+ fouriier features method \n",
    "sample_sizes = 30 * np.arange(1, 10)\n",
    "OneClass_svm_Linear_fourtier_scores = []\n",
    "OneClass_svm_Linear_fourtier_times = []\n",
    "OneClass_svm_Linear_fourtier_auc_scores= []\n",
    "\n",
    "for D in sample_sizes:\n",
    "    OneClass_svm_Linear_fourier.set_params(feature_map__n_components=D)\n",
    "    start = time()\n",
    "    OneClass_svm_Linear_fourier.fit(data_train)\n",
    "    OneClass_svm_Linear_fourtier_times.append(time() - start)\n",
    "    preds = OneClass_svm_Linear_fourier.predict(data_test)  \n",
    "    targs = targets_test\n",
    "    \n",
    "    OneClass_svm_Linear_fourtier_score = metrics.accuracy_score(targs, preds)  \n",
    "    OneClass_svm_Linear_fourtier_scores.append(OneClass_svm_Linear_fourtier_score)\n",
    "    \n",
    "    ## Compute AUC for the FF  classifier performance\n",
    "#     preds = OneClass_svm_Linear_fourier.predict(data_train)  \n",
    "#     targs = targets_train\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(targs, preds)\n",
    "    OneClass_svm_Linear_fourtier_auc_score = metrics.auc(fpr, tpr)\n",
    "    OneClass_svm_Linear_fourtier_auc_scores.append(OneClass_svm_Linear_fourtier_auc_score)\n",
    "#     print \"fourier_approx_svm Classifier AUC:\",fourier_approx_auc_score,fourier_times\n",
    "\n",
    "print \"OneClass_svm_Linear_fourier and predicted...\"\n",
    "print targs\n",
    "print preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from data_fetch import prepare_usps_mlfetch\n",
    "# [Xtrue,Xlabels] = prepare_usps_mlfetch()\n",
    "# data = Xtrue\n",
    "# target = Xlabels\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# train_data, test_data, train_target, test_target = train_test_split(data, target, train_size = 0.8)\n",
    "# train_data.shape\n",
    "\n",
    "\n",
    "# # We learn the digits on the first half of the digits\n",
    "# data_train, targets_train = train_data,train_target\n",
    "# # Now predict the value of the digit on the second half:\n",
    "# data_test, targets_test = test_data,test_target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import tflearn\n",
    "# var= tflearn.variables.get_all_trainable_variable()\n",
    "# print type(var)\n",
    "# for v in var:\n",
    "#     print v\n",
    "print preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75, 0.5, 0.5, 0.75, 0.75, 0.5, 0.5, 0.5, 0.5]\n",
      "[0.69444444444444442, 0.94444444444444442, 0.93333333333333335, 0.91111111111111109, 0.93333333333333335, 0.94444444444444442, 0.91111111111111109, 0.81111111111111112, 0.90000000000000002]\n"
     ]
    }
   ],
   "source": [
    "print fourier_auc_scores\n",
    "print OneClass_svm_Linear_fourtier_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.figure(figsize=(8, 8))\n",
    "# accuracy = plt.subplot(111)\n",
    "# second y axis for timeings\n",
    "# timescale = plt.subplot(111)\n",
    "\n",
    "# print \"OneClassNN\",oneClass_nn_score,oneClass_nn_time\n",
    "# print\"oneClass_svm_score\", oneClass_svm_score,oneClass_svm_time\n",
    "# print\"linear_svm_score\", linear_svm_score,linear_svm_time\n",
    "# print \"kernel_svm_score\", kernel_svm_score,kernel_svm_time\n",
    "# print \"fourier_scores\", np.mean(fourier_scores),np.mean(fourier_times)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# basepath = \"/Users/raghav/Documents/Uni/ECML_2017/experiments/cifar_10/\"\n",
    "mse = np.zeros((1,5))\n",
    "\n",
    "# mse[:,0] = np.asarray(oneClass_svm_score)\n",
    "mse[:,0] = np.asarray(np.mean(OneClass_svm_Linear_fourtier_scores))\n",
    "mse[:,1] = np.asarray(oneClass_svm_score)\n",
    "\n",
    "\n",
    "\n",
    "mse[:,2] = np.asarray(kernel_svm_score)\n",
    "mse[:,3] = np.asarray(np.mean(fourier_scores))\n",
    "mse[:,4] = np.asarray(oneClass_nn_score)\n",
    "\n",
    "df = pd.DataFrame(mse, columns=['OC-SVM-LFF', 'OC-SVM-RBF','RBF-SVM', 'RFF-SVM','OneClass-NN'])\n",
    "df.plot.box()\n",
    "plt.title('Classifier Performance',fontsize=12,fontweight=\"bold\")\n",
    "plt.ylabel(\" Accuracy\",fontsize=12,fontweight=\"bold\")\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the AUC Acore for various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.figure(figsize=(8, 8))\n",
    "# accuracy = plt.subplot(111)\n",
    "# second y axis for timeings\n",
    "# timescale = plt.subplot(111)\n",
    "\n",
    "# print \"OneClassNN\",oneClass_nn_score,oneClass_nn_time\n",
    "# print\"oneClass_svm_score\", oneClass_svm_score,oneClass_svm_time\n",
    "# print\"linear_svm_score\", linear_svm_score,linear_svm_time\n",
    "# print \"kernel_svm_score\", kernel_svm_score,kernel_svm_time\n",
    "# print \"fourier_scores\", np.mean(fourier_scores),np.mean(fourier_times)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# basepath = \"/Users/raghav/Documents/Uni/ECML_2017/experiments/cifar_10/\"\n",
    "mse = np.zeros((1,5))\n",
    "\n",
    "# mse[:,0] = np.asarray(oneClass_svm_auc_score)\n",
    "\n",
    "mse[:,0] = np.asarray(np.mean(OneClass_svm_Linear_fourtier_auc_scores))\n",
    "mse[:,1] = np.asarray(oneClass_svm_auc_score)\n",
    "mse[:,2] = np.asarray(kernel_svm_auc_score)\n",
    "mse[:,3] = np.asarray(np.mean(fourier_auc_scores))\n",
    "mse[:,4] = np.asarray(oneClass_nn_auc_score)\n",
    "\n",
    "df = pd.DataFrame(mse, columns=['OC-SVM-LFF', 'OC-SVM-RBF','RBF-SVM', 'RFF-SVM','OneClass-NN'])\n",
    "df.plot.box()\n",
    "plt.title('Classifier AUC Performance',fontsize=12,fontweight=\"bold\")\n",
    "plt.ylabel(\" AUC\",fontsize=12,fontweight=\"bold\")\n",
    "plt.xticks(rotation=45)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print \" Predictions of One Class NN\"\n",
    "# # print Y_test\n",
    "# # print preds\n",
    "\n",
    "\n",
    "xtestDF_OC_RBF = oneClass_svm.decision_function(X_test)\n",
    "xtestDF_OC_LFF = OneClass_svm_Linear_fourier.decision_function(X_test)\n",
    "\n",
    "print \" One Class SVM - Decision Functions\"\n",
    "print xtestDF_OC_RBF\n",
    "print Y_test\n",
    "print \" ##############################################\"\n",
    "print xtestDF_OC_LFF\n",
    "print Y_test\n",
    "## But how can we know the decision function for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### PLotting the decision functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.font_manager\n",
    "# from sklearn import svm\n",
    "\n",
    "# nx, ny = (len(data), 256)\n",
    "# x = np.linspace(-1, 1, nx)\n",
    "# y = np.linspace(-1, 1, ny)\n",
    "# xx, yy =  np.meshgrid(x, y)\n",
    "\n",
    "# # xx, yy = np.meshgrid(np.linspace(-1, 1, 231), np.linspace(-1, 1, 231))\n",
    "# ### Synthetic Data\n",
    "# # # Generate train data\n",
    "# # X = 0.3 * np.random.randn(100, 2)\n",
    "# # X_train = np.r_[X + 2, X - 2]\n",
    "# # # Generate some regular novel observations\n",
    "# # X = 0.3 * np.random.randn(20, 2)\n",
    "# # X_test = np.r_[X + 2, X - 2]\n",
    "# # # Generate some abnormal novel observations\n",
    "# # X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
    "\n",
    "# ## USPS Data\n",
    "# X_train = data[0:180]\n",
    "# X_test = data[181:219]\n",
    "# X_outliers = data[220:231]\n",
    "\n",
    "\n",
    "# # fit the model\n",
    "# clf = svm.OneClassSVM(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "# clf.fit(X_train)\n",
    "# y_pred_train = clf.predict(X_train)\n",
    "# y_pred_test = clf.predict(X_test)\n",
    "# y_pred_outliers = clf.predict(X_outliers)\n",
    "# n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "# n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "# n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size\n",
    "\n",
    "# # plot the line, the points, and the nearest vectors to the plane\n",
    "# Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Z = Z.reshape(xx.shape)\n",
    "\n",
    "# plt.title(\"Novelty Detection\")\n",
    "# plt.contourf(xx, yy, Z, levels=np.linspace(Z.min(), 0, 7), cmap=plt.cm.Blues_r)\n",
    "# a = plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='red')\n",
    "# plt.contourf(xx, yy, Z, levels=[0, Z.max()], colors='orange')\n",
    "\n",
    "# b1 = plt.scatter(X_train[:, 0], X_train[:, 1], c='white')\n",
    "# b2 = plt.scatter(X_test[:, 0], X_test[:, 1], c='green')\n",
    "# c = plt.scatter(X_outliers[:, 0], X_outliers[:, 1], c='red')\n",
    "# plt.axis('tight')\n",
    "# plt.xlim((-1, 1))\n",
    "# plt.ylim((-1, 1))\n",
    "# plt.legend([a.collections[0], b1, b2, c],\n",
    "#            [\"learned frontier\", \"training observations\",\n",
    "#             \"new regular observations\", \"new abnormal observations\"],\n",
    "#            loc=\"upper left\",\n",
    "#            prop=matplotlib.font_manager.FontProperties(size=11))\n",
    "# plt.xlabel(\n",
    "#     \"error train: %d/200 ; errors novel regular: %d/40 ; \"\n",
    "#     \"errors novel abnormal: %d/40\"\n",
    "#     % (n_error_train, n_error_test, n_error_outliers))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
